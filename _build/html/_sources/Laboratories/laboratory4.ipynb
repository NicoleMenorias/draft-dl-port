{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2943b48",
   "metadata": {},
   "source": [
    "# **Laboratory Task 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63337789",
   "metadata": {},
   "source": [
    "**Instruction:** Train a linear regression model in PyTorch using a regression dataset. Use the following parameters.\n",
    "\n",
    "* Criterion: MSE Loss\n",
    "* Fully Connected Layers x 2\n",
    "* Batch Size: 8\n",
    "* Optimizer: SGD\n",
    "* Epoch: 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96bdb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1eda903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (regression dataset: Diabetes)\n",
    "diabetes = load_diabetes()\n",
    "X = diabetes.data\n",
    "y = diabetes.target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcae2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.8005,  1.0655,  1.2971,  0.4598, -0.9297, -0.7321, -0.9125, -0.0545,\n",
      "          0.4185, -0.3710],\n",
      "        [-0.0396, -0.9385, -1.0822, -0.5535, -0.1776, -0.4029,  1.5644, -0.8303,\n",
      "         -1.4366, -1.9385],\n",
      "        [ 1.7933,  1.0655,  0.9345, -0.1192, -0.9587, -0.7189, -0.6802, -0.0545,\n",
      "          0.0602, -0.5452],\n",
      "        [-1.8724, -0.9385, -0.2438, -0.7706,  0.2563,  0.5254, -0.7576,  0.7213,\n",
      "          0.4770, -0.1968],\n",
      "        [ 0.1132, -0.9385, -0.7649,  0.4598,  0.0827,  0.3279,  0.1712, -0.0545,\n",
      "         -0.6725, -0.9806]]) tensor([[151.],\n",
      "        [ 75.],\n",
      "        [141.],\n",
      "        [206.],\n",
      "        [135.]])\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "print(X_tensor[:5], y_tensor[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36d163c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoader\n",
    "train_data = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d426bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model (2 fully connected layers)\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(X.shape[1], 16)  # input -> hidden\n",
    "        self.fc2 = nn.Linear(16, 1)           # hidden -> output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2659456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0e7bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c87020d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 4643.3945\n",
      "Epoch [200/1000], Loss: 4648.6738\n",
      "Epoch [300/1000], Loss: 1040.4867\n",
      "Epoch [400/1000], Loss: 1212.6029\n",
      "Epoch [500/1000], Loss: 552.4731\n",
      "Epoch [600/1000], Loss: 1917.4807\n",
      "Epoch [700/1000], Loss: 2580.8015\n",
      "Epoch [800/1000], Loss: 947.7831\n",
      "Epoch [900/1000], Loss: 3790.8884\n",
      "Epoch [1000/1000], Loss: 1367.9885\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69731eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Test Loss (MSE): 3363.6987\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test data\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test).item()\n",
    "\n",
    "print(f\"\\nFinal Test Loss (MSE): {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc4f45",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- Training loss shows **large fluctuations** (e.g., ~18 at epoch 300 but >6000 at epoch 500), indicating instability with SGD on small batches.  \n",
    "- Despite fluctuations, the model can occasionally reach **very low training losses (~15)**, meaning it has the capacity to fit the dataset.  \n",
    "- The **final training loss (~14.9)** is much lower than the early epochs, showing the model does learn patterns over time.  \n",
    "- The **final test loss (~2920.8)** is high compared to training loss, suggesting **overfitting** and poor generalization.  \n",
    "- Using the Diabetes dataset (small sample size, noisy target) contributes to unstable convergence.  \n",
    "- Two fully connected layers give the model more flexibility, but with **SGD (no momentum)** and **batch size of 8**, the optimization remains noisy.  \n",
    "- Overall: the model fits training data but struggles to generalize, highlighting dataset limitations and optimizer instability.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cardio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
